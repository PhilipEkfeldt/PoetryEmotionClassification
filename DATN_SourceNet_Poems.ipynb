{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the source network on the poems (frozen weights from songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_processing\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from imp import reload\n",
    "import models\n",
    "reload(models)\n",
    "from text_processing import read_split_file_lyrics, BatchWrapper, generate_iterators_lyrics, generate_iterators\n",
    "from functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating iterators.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating iterators.\")\n",
    "#Create iterators\n",
    "emotions= ['anger', 'anticipation', 'fear', 'joy', 'love', 'optimism', 'pess', 'sad']\n",
    "torch.cuda.empty_cache() \n",
    "batch_size = 10\n",
    "train_iter_p, val_iter_p, test_iter_p, TEXT = generate_iterators(\"split_used_for_baseline/poems_train.csv\", \"split_used_for_baseline/poems_val.csv\",\n",
    "                                                                  \"split_used_for_baseline/poems_test.csv\", batch_size = batch_size, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_src = 0.350748\n",
    "learning_rate_src = 0.000146\n",
    "hidden_dim_src = 183\n",
    "v_dim_src = 21\n",
    "label_size_src = 2\n",
    "label_size = 8\n",
    "embedding_dim_src = 300\n",
    "\n",
    "\n",
    "train_batch = BatchWrapper(train_iter_p, \"text\", emotions)\n",
    "valid_batch = BatchWrapper(val_iter_p, \"text\", emotions)\n",
    "test_batch = BatchWrapper(test_iter_p, \"text\", emotions)\n",
    "\n",
    "m_source_p = BiLSTMSourceNet(vocab_size = len(TEXT.vocab), embedding_dim = embedding_dim_src, \n",
    "                               hidden_dim = hidden_dim_src, label_size=label_size_src, v_dim = v_dim_src, \n",
    "                               pretrained_vec=TEXT.vocab.vectors, use_gpu = True, dropout = dropout_src)\n",
    "\n",
    "m_source_p.to(\"cuda\")\n",
    "src_model_dict = torch.load(\"SourceNetModelDict_Final.pth\")\n",
    "src_model_dict['embeddings.weight'] = TEXT.vocab.vectors\n",
    "# src_model_dict['decoder.bias'] = torch.ones(8)\n",
    "# src_model_dict['decoder.weight'] = torch.ones(8, hidden_dim*2)\n",
    "m_source_p.load_state_dict(src_model_dict)\n",
    "\n",
    "for param in m_source_p.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashr\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1992: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "C:\\Users\\yashr\\Documents\\Poetry_DATN\\functions.py:137: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(tgt_model.parameters(), 5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.801196; Dev loss 0.578877; Dev acc: 0.214286; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.077354; Dev loss 0.515957; Dev acc: 0.093750; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.771158; Dev loss 0.536134; Dev acc: 0.209821; Test acc: 0.234043\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.485437; Dev loss 0.525228; Dev acc: 0.205357; Test acc: 0.244681\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.612291; Dev loss 0.541859; Dev acc: 0.205357; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.651474; Dev loss 0.529813; Dev acc: 0.093750; Test acc: 0.063830\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.674862; Dev loss 0.530963; Dev acc: 0.129464; Test acc: 0.152482\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.988408; Dev loss 0.526667; Dev acc: 0.267857; Test acc: 0.223404\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss nan; Dev loss nan; Dev acc: 0.013393; Test acc: 0.007092\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss nan; Dev loss nan; Dev acc: 0.040179; Test acc: 0.035461\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss nan; Dev loss nan; Dev acc: 0.022321; Test acc: 0.014184\n",
      "Iteration: 2\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.902946; Dev loss 0.620230; Dev acc: 0.138393; Test acc: 0.145390\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.926761; Dev loss 0.599285; Dev acc: 0.125000; Test acc: 0.248227\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.380708; Dev loss 0.550973; Dev acc: 0.089286; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.485131; Dev loss 0.587641; Dev acc: 0.142857; Test acc: 0.191489\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.169429; Dev loss 0.613933; Dev acc: 0.125000; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.562281; Dev loss 0.551069; Dev acc: 0.089286; Test acc: 0.109929\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.560325; Dev loss 0.529902; Dev acc: 0.125000; Test acc: 0.145390\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.712934; Dev loss 0.524146; Dev acc: 0.151786; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.231510; Dev loss 0.550771; Dev acc: 0.129464; Test acc: 0.223404\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.408645; Dev loss 0.536587; Dev acc: 0.200893; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.200062; Dev loss 0.570922; Dev acc: 0.196429; Test acc: 0.304965\n",
      "Iteration: 3\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.582682; Dev loss 0.520725; Dev acc: 0.111607; Test acc: 0.060284\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.881782; Dev loss 0.510573; Dev acc: 0.348214; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.845685; Dev loss 0.521982; Dev acc: 0.294643; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.687585; Dev loss 0.527736; Dev acc: 0.098214; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.921734; Dev loss 0.517054; Dev acc: 0.174107; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.712226; Dev loss 0.524620; Dev acc: 0.107143; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.089344; Dev loss 0.530026; Dev acc: 0.205357; Test acc: 0.361702\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.665859; Dev loss 0.510851; Dev acc: 0.343750; Test acc: 0.358156\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.377157; Dev loss 0.518919; Dev acc: 0.276786; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.077523; Dev loss 0.544812; Dev acc: 0.129464; Test acc: 0.163121\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.695963; Dev loss 0.541112; Dev acc: 0.160714; Test acc: 0.209220\n",
      "Iteration: 4\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.590574; Dev loss 0.622211; Dev acc: 0.263393; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.685437; Dev loss 0.547026; Dev acc: 0.200893; Test acc: 0.205674\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.809480; Dev loss 0.541012; Dev acc: 0.245536; Test acc: 0.308511\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.237811; Dev loss 0.609535; Dev acc: 0.147321; Test acc: 0.234043\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.644305; Dev loss 0.553168; Dev acc: 0.107143; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.187894; Dev loss 0.562483; Dev acc: 0.205357; Test acc: 0.258865\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.056777; Dev loss 0.558082; Dev acc: 0.066964; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.877927; Dev loss 0.627518; Dev acc: 0.102679; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.427724; Dev loss 0.663879; Dev acc: 0.044643; Test acc: 0.152482\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.599220; Dev loss 0.720631; Dev acc: 0.093750; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.537780; Dev loss 0.576820; Dev acc: 0.125000; Test acc: 0.131206\n",
      "Iteration: 5\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.008702; Dev loss 0.506484; Dev acc: 0.281250; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.215277; Dev loss 0.521521; Dev acc: 0.174107; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.824942; Dev loss 0.515804; Dev acc: 0.058036; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.186042; Dev loss 0.533871; Dev acc: 0.066964; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.995423; Dev loss 0.516520; Dev acc: 0.267857; Test acc: 0.333333\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.609155; Dev loss 0.527534; Dev acc: 0.227679; Test acc: 0.287234\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.640724; Dev loss 0.511985; Dev acc: 0.254464; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.671973; Dev loss 0.519695; Dev acc: 0.245536; Test acc: 0.400709\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.400162; Dev loss 0.515077; Dev acc: 0.241071; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.489042; Dev loss 0.517067; Dev acc: 0.254464; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.870012; Dev loss 0.509069; Dev acc: 0.276786; Test acc: 0.336879\n",
      "Iteration: 6\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.748969; Dev loss 0.577118; Dev acc: 0.138393; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.475806; Dev loss 0.579096; Dev acc: 0.071429; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.635778; Dev loss 0.607774; Dev acc: 0.071429; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.295110; Dev loss 0.545409; Dev acc: 0.187500; Test acc: 0.216312\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.796950; Dev loss 0.535569; Dev acc: 0.120536; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.750360; Dev loss 0.642315; Dev acc: 0.294643; Test acc: 0.269504\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.438272; Dev loss 0.550330; Dev acc: 0.183036; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.616519; Dev loss 0.592705; Dev acc: 0.098214; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test..\n",
      "Epoch 8; Loss 2.293877; Dev loss 0.580496; Dev acc: 0.142857; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.661786; Dev loss 0.557889; Dev acc: 0.236607; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.487230; Dev loss 0.631507; Dev acc: 0.147321; Test acc: 0.124113\n",
      "Iteration: 7\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.412807; Dev loss 0.506284; Dev acc: 0.348214; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.585972; Dev loss 0.533006; Dev acc: 0.321429; Test acc: 0.386525\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.332862; Dev loss 0.508759; Dev acc: 0.303571; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.956816; Dev loss 0.524665; Dev acc: 0.250000; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.931747; Dev loss 0.540085; Dev acc: 0.267857; Test acc: 0.368794\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.262200; Dev loss 0.536761; Dev acc: 0.263393; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.151290; Dev loss 0.535834; Dev acc: 0.236607; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.870771; Dev loss 0.509493; Dev acc: 0.285714; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.071491; Dev loss 0.515152; Dev acc: 0.303571; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.551954; Dev loss 0.508662; Dev acc: 0.241071; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.264371; Dev loss 0.515719; Dev acc: 0.254464; Test acc: 0.308511\n",
      "Iteration: 8\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.999189; Dev loss 0.515892; Dev acc: 0.241071; Test acc: 0.304965\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.353240; Dev loss 0.512335; Dev acc: 0.308036; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.561141; Dev loss 0.514642; Dev acc: 0.290179; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.567312; Dev loss 0.508287; Dev acc: 0.294643; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.066220; Dev loss 0.522550; Dev acc: 0.214286; Test acc: 0.195035\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.955441; Dev loss 0.524381; Dev acc: 0.241071; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.869457; Dev loss 0.509701; Dev acc: 0.321429; Test acc: 0.304965\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.406718; Dev loss 0.514788; Dev acc: 0.308036; Test acc: 0.283688\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.520691; Dev loss 0.507361; Dev acc: 0.321429; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.603321; Dev loss 0.529756; Dev acc: 0.258929; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.042328; Dev loss 0.531119; Dev acc: 0.209821; Test acc: 0.273050\n",
      "Iteration: 9\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.889095; Dev loss 0.563353; Dev acc: 0.303571; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.595424; Dev loss 0.540039; Dev acc: 0.245536; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.964401; Dev loss 0.534782; Dev acc: 0.075893; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.877118; Dev loss 0.512199; Dev acc: 0.308036; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.389840; Dev loss 0.517689; Dev acc: 0.285714; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.847051; Dev loss 0.511028; Dev acc: 0.174107; Test acc: 0.205674\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 4.212928; Dev loss 0.520658; Dev acc: 0.250000; Test acc: 0.262411\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.752250; Dev loss 0.531743; Dev acc: 0.191964; Test acc: 0.262411\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.482243; Dev loss 0.517468; Dev acc: 0.303571; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.625230; Dev loss 0.535236; Dev acc: 0.250000; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.432906; Dev loss 0.529610; Dev acc: 0.267857; Test acc: 0.308511\n",
      "Iteration: 10\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.178339; Dev loss 0.536883; Dev acc: 0.276786; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.097296; Dev loss 0.527094; Dev acc: 0.272321; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.828032; Dev loss 0.535721; Dev acc: 0.325893; Test acc: 0.304965\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.891239; Dev loss 0.522758; Dev acc: 0.116071; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.017742; Dev loss 0.521616; Dev acc: 0.263393; Test acc: 0.287234\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.544075; Dev loss 0.526416; Dev acc: 0.183036; Test acc: 0.195035\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.656992; Dev loss 0.520268; Dev acc: 0.120536; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.657265; Dev loss 0.515710; Dev acc: 0.285714; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.706690; Dev loss 0.567019; Dev acc: 0.098214; Test acc: 0.138298\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.613765; Dev loss 0.544231; Dev acc: 0.125000; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.564002; Dev loss 0.546666; Dev acc: 0.142857; Test acc: 0.138298\n",
      "Iteration: 11\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.736960; Dev loss 0.504463; Dev acc: 0.325893; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.436026; Dev loss 0.527860; Dev acc: 0.245536; Test acc: 0.333333\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.463742; Dev loss 0.511622; Dev acc: 0.294643; Test acc: 0.365248\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.784677; Dev loss 0.524138; Dev acc: 0.276786; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.527539; Dev loss 0.513050; Dev acc: 0.325893; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.871089; Dev loss 0.512201; Dev acc: 0.316964; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.199876; Dev loss 0.509190; Dev acc: 0.321429; Test acc: 0.308511\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.921491; Dev loss 0.506685; Dev acc: 0.276786; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.481195; Dev loss 0.516691; Dev acc: 0.272321; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.393282; Dev loss 0.507402; Dev acc: 0.299107; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.645885; Dev loss 0.516214; Dev acc: 0.254464; Test acc: 0.333333\n",
      "Iteration: 12\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.939010; Dev loss 0.575220; Dev acc: 0.066964; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.843905; Dev loss 0.536695; Dev acc: 0.084821; Test acc: 0.067376\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.244180; Dev loss 0.540224; Dev acc: 0.254464; Test acc: 0.269504\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.612981; Dev loss 0.508697; Dev acc: 0.236607; Test acc: 0.244681\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.278664; Dev loss 0.526392; Dev acc: 0.062500; Test acc: 0.102837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.715331; Dev loss 0.526091; Dev acc: 0.258929; Test acc: 0.287234\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.552318; Dev loss 0.534911; Dev acc: 0.214286; Test acc: 0.358156\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.269428; Dev loss 0.528245; Dev acc: 0.133929; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.522158; Dev loss 0.505724; Dev acc: 0.156250; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.114169; Dev loss 0.559512; Dev acc: 0.169643; Test acc: 0.265957\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.301327; Dev loss 0.551267; Dev acc: 0.142857; Test acc: 0.191489\n",
      "Iteration: 13\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.897138; Dev loss 0.547477; Dev acc: 0.093750; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.935231; Dev loss 0.503798; Dev acc: 0.254464; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.435724; Dev loss 0.533858; Dev acc: 0.303571; Test acc: 0.365248\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.565730; Dev loss 0.518464; Dev acc: 0.276786; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.162339; Dev loss 0.524846; Dev acc: 0.254464; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.039538; Dev loss 0.525349; Dev acc: 0.294643; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.201281; Dev loss 0.514007; Dev acc: 0.290179; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.396034; Dev loss 0.524583; Dev acc: 0.241071; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.510039; Dev loss 0.511954; Dev acc: 0.316964; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.668262; Dev loss 0.532266; Dev acc: 0.267857; Test acc: 0.372340\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.735244; Dev loss 0.510056; Dev acc: 0.200893; Test acc: 0.205674\n",
      "Iteration: 14\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.603752; Dev loss 0.516835; Dev acc: 0.062500; Test acc: 0.074468\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.598574; Dev loss 0.557606; Dev acc: 0.026786; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.450470; Dev loss 0.512818; Dev acc: 0.254464; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.162409; Dev loss 0.528315; Dev acc: 0.223214; Test acc: 0.241135\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.614981; Dev loss 0.510659; Dev acc: 0.267857; Test acc: 0.262411\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.643727; Dev loss 0.518970; Dev acc: 0.098214; Test acc: 0.106383\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.658008; Dev loss 0.537443; Dev acc: 0.290179; Test acc: 0.216312\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.595439; Dev loss 0.528992; Dev acc: 0.138393; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.744959; Dev loss 0.527272; Dev acc: 0.209821; Test acc: 0.333333\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.570999; Dev loss 0.531132; Dev acc: 0.075893; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.666072; Dev loss 0.553058; Dev acc: 0.254464; Test acc: 0.287234\n",
      "Iteration: 15\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.436253; Dev loss 0.540754; Dev acc: 0.080357; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.266643; Dev loss 0.530641; Dev acc: 0.281250; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.664210; Dev loss 0.554606; Dev acc: 0.107143; Test acc: 0.109929\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.409763; Dev loss 0.524924; Dev acc: 0.267857; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.978716; Dev loss 0.543426; Dev acc: 0.120536; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.806728; Dev loss 0.537834; Dev acc: 0.258929; Test acc: 0.265957\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.074294; Dev loss 0.552890; Dev acc: 0.178571; Test acc: 0.255319\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.422068; Dev loss 0.555878; Dev acc: 0.147321; Test acc: 0.198582\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.615146; Dev loss 0.565145; Dev acc: 0.232143; Test acc: 0.248227\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.484955; Dev loss 0.580961; Dev acc: 0.227679; Test acc: 0.269504\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.725205; Dev loss 0.571606; Dev acc: 0.169643; Test acc: 0.177305\n",
      "Iteration: 16\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.336861; Dev loss 0.532386; Dev acc: 0.044643; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.938595; Dev loss 0.532272; Dev acc: 0.241071; Test acc: 0.404255\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.137068; Dev loss 0.520749; Dev acc: 0.049107; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.789187; Dev loss 0.527322; Dev acc: 0.258929; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.030958; Dev loss 0.518055; Dev acc: 0.285714; Test acc: 0.347518\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.245204; Dev loss 0.518552; Dev acc: 0.272321; Test acc: 0.372340\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.771753; Dev loss 0.531703; Dev acc: 0.263393; Test acc: 0.375887\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.325437; Dev loss 0.527738; Dev acc: 0.263393; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.651180; Dev loss 0.514830; Dev acc: 0.071429; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.328239; Dev loss 0.513271; Dev acc: 0.294643; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.662494; Dev loss 0.519491; Dev acc: 0.084821; Test acc: 0.152482\n",
      "Iteration: 17\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.654153; Dev loss 0.555337; Dev acc: 0.254464; Test acc: 0.223404\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.605945; Dev loss 0.524701; Dev acc: 0.049107; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.417578; Dev loss 0.521569; Dev acc: 0.281250; Test acc: 0.365248\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.510663; Dev loss 0.521979; Dev acc: 0.272321; Test acc: 0.393617\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.554953; Dev loss 0.521796; Dev acc: 0.258929; Test acc: 0.209220\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.759156; Dev loss 0.513199; Dev acc: 0.227679; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.413418; Dev loss 0.525842; Dev acc: 0.236607; Test acc: 0.304965\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.232949; Dev loss 0.530982; Dev acc: 0.263393; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.868761; Dev loss 0.518636; Dev acc: 0.142857; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.402958; Dev loss 0.530596; Dev acc: 0.196429; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.558227; Dev loss 0.550689; Dev acc: 0.241071; Test acc: 0.333333\n",
      "Iteration: 18\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.433677; Dev loss 0.534187; Dev acc: 0.191964; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1; Loss 2.381516; Dev loss 0.586209; Dev acc: 0.178571; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.126442; Dev loss 0.545542; Dev acc: 0.209821; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.699561; Dev loss 0.557375; Dev acc: 0.098214; Test acc: 0.106383\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.208155; Dev loss 0.609887; Dev acc: 0.107143; Test acc: 0.191489\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.867801; Dev loss 0.543724; Dev acc: 0.250000; Test acc: 0.205674\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.768852; Dev loss 0.522866; Dev acc: 0.156250; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.660548; Dev loss 0.602643; Dev acc: 0.165179; Test acc: 0.205674\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.534089; Dev loss 0.574627; Dev acc: 0.214286; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.696713; Dev loss 0.660456; Dev acc: 0.303571; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.597247; Dev loss 0.583746; Dev acc: 0.129464; Test acc: 0.092199\n",
      "Iteration: 19\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.067799; Dev loss 0.517757; Dev acc: 0.263393; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.312466; Dev loss 0.554198; Dev acc: 0.084821; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.675959; Dev loss 0.521978; Dev acc: 0.250000; Test acc: 0.280142\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.453578; Dev loss 0.553019; Dev acc: 0.245536; Test acc: 0.195035\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.679204; Dev loss 0.513781; Dev acc: 0.316964; Test acc: 0.375887\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.811558; Dev loss 0.540197; Dev acc: 0.165179; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.739650; Dev loss 0.535249; Dev acc: 0.093750; Test acc: 0.148936\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.672909; Dev loss 0.526215; Dev acc: 0.223214; Test acc: 0.198582\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.689308; Dev loss 0.540469; Dev acc: 0.191964; Test acc: 0.216312\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.512837; Dev loss 0.560850; Dev acc: 0.303571; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.392708; Dev loss 0.538308; Dev acc: 0.040179; Test acc: 0.060284\n",
      "Iteration: 20\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.506398; Dev loss 0.524244; Dev acc: 0.044643; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.531288; Dev loss 0.513934; Dev acc: 0.227679; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.079342; Dev loss 0.517390; Dev acc: 0.214286; Test acc: 0.347518\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.994217; Dev loss 0.509906; Dev acc: 0.308036; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.962718; Dev loss 0.532559; Dev acc: 0.258929; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.493887; Dev loss 0.515152; Dev acc: 0.125000; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.491420; Dev loss 0.515107; Dev acc: 0.267857; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.707690; Dev loss 0.522939; Dev acc: 0.080357; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.668640; Dev loss 0.513435; Dev acc: 0.294643; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.188191; Dev loss 0.518771; Dev acc: 0.129464; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.531808; Dev loss 0.524937; Dev acc: 0.125000; Test acc: 0.145390\n",
      "Iteration: 21\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.402997; Dev loss 0.513722; Dev acc: 0.285714; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.505206; Dev loss 0.523688; Dev acc: 0.075893; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.631089; Dev loss 0.506100; Dev acc: 0.254464; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.705015; Dev loss 0.524005; Dev acc: 0.258929; Test acc: 0.375887\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.553468; Dev loss 0.517592; Dev acc: 0.084821; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.345322; Dev loss 0.526294; Dev acc: 0.290179; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.356339; Dev loss 0.519641; Dev acc: 0.281250; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.722158; Dev loss 0.533175; Dev acc: 0.272321; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.718340; Dev loss 0.520472; Dev acc: 0.151786; Test acc: 0.209220\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.532369; Dev loss 0.527835; Dev acc: 0.120536; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.357555; Dev loss 0.523698; Dev acc: 0.156250; Test acc: 0.287234\n",
      "Iteration: 22\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.171433; Dev loss 0.611865; Dev acc: 0.294643; Test acc: 0.386525\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.253986; Dev loss 0.554902; Dev acc: 0.187500; Test acc: 0.262411\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.953294; Dev loss 0.559180; Dev acc: 0.160714; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.140424; Dev loss 0.716267; Dev acc: 0.129464; Test acc: 0.202128\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.619007; Dev loss 0.581192; Dev acc: 0.178571; Test acc: 0.195035\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.972946; Dev loss 0.594036; Dev acc: 0.196429; Test acc: 0.223404\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.705169; Dev loss 0.647640; Dev acc: 0.129464; Test acc: 0.145390\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.294128; Dev loss 0.567964; Dev acc: 0.250000; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.237176; Dev loss 0.571399; Dev acc: 0.183036; Test acc: 0.145390\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.070140; Dev loss 0.591944; Dev acc: 0.236607; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.332656; Dev loss 0.618431; Dev acc: 0.209821; Test acc: 0.209220\n",
      "Iteration: 23\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.794929; Dev loss 0.529919; Dev acc: 0.178571; Test acc: 0.202128\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.921757; Dev loss 0.573313; Dev acc: 0.214286; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.718140; Dev loss 0.572848; Dev acc: 0.089286; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.722555; Dev loss 0.592383; Dev acc: 0.116071; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.475851; Dev loss 0.656444; Dev acc: 0.138393; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.566613; Dev loss 0.590053; Dev acc: 0.191964; Test acc: 0.202128\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.327356; Dev loss 0.573124; Dev acc: 0.125000; Test acc: 0.085106\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.442345; Dev loss 0.669646; Dev acc: 0.120536; Test acc: 0.212766\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.681147; Dev loss 0.604791; Dev acc: 0.205357; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test..\n",
      "Epoch 9; Loss 3.210902; Dev loss 0.623194; Dev acc: 0.254464; Test acc: 0.191489\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.569082; Dev loss 0.606416; Dev acc: 0.263393; Test acc: 0.223404\n",
      "Iteration: 24\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.697037; Dev loss 0.882670; Dev acc: 0.062500; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.241511; Dev loss 0.611708; Dev acc: 0.160714; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.682572; Dev loss 0.621644; Dev acc: 0.125000; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.966319; Dev loss 0.617005; Dev acc: 0.147321; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.475490; Dev loss 0.577225; Dev acc: 0.205357; Test acc: 0.202128\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.852625; Dev loss 0.588233; Dev acc: 0.187500; Test acc: 0.216312\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.609208; Dev loss 0.551679; Dev acc: 0.183036; Test acc: 0.237589\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.166520; Dev loss 0.554116; Dev acc: 0.191964; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.222938; Dev loss 0.542132; Dev acc: 0.151786; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.716637; Dev loss 0.549177; Dev acc: 0.102679; Test acc: 0.163121\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.696601; Dev loss 0.576927; Dev acc: 0.147321; Test acc: 0.106383\n",
      "Iteration: 25\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.866127; Dev loss 0.700958; Dev acc: 0.066964; Test acc: 0.106383\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.487833; Dev loss 0.655600; Dev acc: 0.178571; Test acc: 0.198582\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.543318; Dev loss 0.638043; Dev acc: 0.089286; Test acc: 0.085106\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 4.045521; Dev loss 0.761367; Dev acc: 0.075893; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.392978; Dev loss 0.584915; Dev acc: 0.308036; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.258771; Dev loss 0.559915; Dev acc: 0.151786; Test acc: 0.163121\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.492548; Dev loss 0.528017; Dev acc: 0.147321; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.621117; Dev loss 0.588066; Dev acc: 0.214286; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.706330; Dev loss 0.619000; Dev acc: 0.133929; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.796436; Dev loss 0.517286; Dev acc: 0.294643; Test acc: 0.163121\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.752957; Dev loss 0.590319; Dev acc: 0.169643; Test acc: 0.258865\n",
      "Iteration: 26\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.552490; Dev loss 0.529953; Dev acc: 0.245536; Test acc: 0.280142\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.668108; Dev loss 0.534855; Dev acc: 0.098214; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.069747; Dev loss 0.507962; Dev acc: 0.290179; Test acc: 0.308511\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.314617; Dev loss 0.524017; Dev acc: 0.111607; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.794345; Dev loss 0.521404; Dev acc: 0.281250; Test acc: 0.418440\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.325030; Dev loss 0.526313; Dev acc: 0.250000; Test acc: 0.333333\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.839322; Dev loss 0.515882; Dev acc: 0.263393; Test acc: 0.358156\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.878034; Dev loss 0.512474; Dev acc: 0.267857; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.583806; Dev loss 0.517107; Dev acc: 0.232143; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.153643; Dev loss 0.526199; Dev acc: 0.151786; Test acc: 0.212766\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.958705; Dev loss 0.514960; Dev acc: 0.312500; Test acc: 0.319149\n",
      "Iteration: 27\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.399946; Dev loss 0.516918; Dev acc: 0.205357; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.648973; Dev loss 0.516462; Dev acc: 0.272321; Test acc: 0.287234\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.598187; Dev loss 0.514572; Dev acc: 0.276786; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.402891; Dev loss 0.540380; Dev acc: 0.254464; Test acc: 0.361702\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.169453; Dev loss 0.522315; Dev acc: 0.053571; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.135103; Dev loss 0.517215; Dev acc: 0.258929; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.656922; Dev loss 0.505926; Dev acc: 0.276786; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.613747; Dev loss 0.516932; Dev acc: 0.267857; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.550220; Dev loss 0.512195; Dev acc: 0.308036; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.496509; Dev loss 0.511833; Dev acc: 0.254464; Test acc: 0.368794\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.865132; Dev loss 0.522555; Dev acc: 0.267857; Test acc: 0.329787\n",
      "Iteration: 28\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.472308; Dev loss 0.525105; Dev acc: 0.053571; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.821238; Dev loss 0.515744; Dev acc: 0.308036; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.006095; Dev loss 0.510281; Dev acc: 0.129464; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.736907; Dev loss 0.527049; Dev acc: 0.285714; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.291658; Dev loss 0.586797; Dev acc: 0.062500; Test acc: 0.166667\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.419405; Dev loss 0.520350; Dev acc: 0.129464; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.214560; Dev loss 0.531993; Dev acc: 0.276786; Test acc: 0.223404\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.721303; Dev loss 0.522731; Dev acc: 0.250000; Test acc: 0.234043\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.339374; Dev loss 0.526282; Dev acc: 0.276786; Test acc: 0.241135\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.497425; Dev loss 0.546990; Dev acc: 0.138393; Test acc: 0.180851\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.178633; Dev loss 0.528032; Dev acc: 0.232143; Test acc: 0.237589\n",
      "Iteration: 29\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.451055; Dev loss 0.507420; Dev acc: 0.138393; Test acc: 0.152482\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.760474; Dev loss 0.548676; Dev acc: 0.205357; Test acc: 0.237589\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.503477; Dev loss 0.516047; Dev acc: 0.223214; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.384186; Dev loss 0.535260; Dev acc: 0.223214; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.211064; Dev loss 0.533267; Dev acc: 0.272321; Test acc: 0.382979\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.265038; Dev loss 0.542920; Dev acc: 0.236607; Test acc: 0.297872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.710038; Dev loss 0.529849; Dev acc: 0.267857; Test acc: 0.333333\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.632493; Dev loss 0.534273; Dev acc: 0.267857; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.042236; Dev loss 0.530253; Dev acc: 0.089286; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.534323; Dev loss 0.527179; Dev acc: 0.129464; Test acc: 0.141844\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.751956; Dev loss 0.537423; Dev acc: 0.232143; Test acc: 0.283688\n",
      "Iteration: 30\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.270710; Dev loss 0.568915; Dev acc: 0.174107; Test acc: 0.209220\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.944128; Dev loss 0.531668; Dev acc: 0.196429; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.272223; Dev loss 0.539157; Dev acc: 0.075893; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.789100; Dev loss 0.583319; Dev acc: 0.133929; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.764969; Dev loss 0.541938; Dev acc: 0.276786; Test acc: 0.258865\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.136611; Dev loss 0.551951; Dev acc: 0.116071; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.804273; Dev loss 0.583351; Dev acc: 0.187500; Test acc: 0.202128\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.609825; Dev loss 0.628299; Dev acc: 0.129464; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.695139; Dev loss 0.657581; Dev acc: 0.183036; Test acc: 0.166667\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.467339; Dev loss 0.672465; Dev acc: 0.236607; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.269456; Dev loss 0.710769; Dev acc: 0.169643; Test acc: 0.212766\n",
      "Iteration: 31\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.429772; Dev loss 0.506195; Dev acc: 0.294643; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.553184; Dev loss 0.535341; Dev acc: 0.294643; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.919650; Dev loss 0.522853; Dev acc: 0.111607; Test acc: 0.060284\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.558356; Dev loss 0.557739; Dev acc: 0.053571; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.865905; Dev loss 0.518727; Dev acc: 0.303571; Test acc: 0.280142\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.116012; Dev loss 0.510365; Dev acc: 0.290179; Test acc: 0.241135\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.240386; Dev loss 0.532138; Dev acc: 0.236607; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.510305; Dev loss 0.517031; Dev acc: 0.183036; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.442167; Dev loss 0.519463; Dev acc: 0.276786; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.894542; Dev loss 0.514457; Dev acc: 0.276786; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.885123; Dev loss 0.519215; Dev acc: 0.174107; Test acc: 0.141844\n",
      "Iteration: 32\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.378643; Dev loss 0.536707; Dev acc: 0.071429; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.931092; Dev loss 0.571615; Dev acc: 0.227679; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.776482; Dev loss 0.611578; Dev acc: 0.196429; Test acc: 0.255319\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.433613; Dev loss 0.514687; Dev acc: 0.196429; Test acc: 0.223404\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.069158; Dev loss 0.589785; Dev acc: 0.191964; Test acc: 0.280142\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.816738; Dev loss 0.579209; Dev acc: 0.169643; Test acc: 0.219858\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.591179; Dev loss 0.617063; Dev acc: 0.191964; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.797107; Dev loss 0.546903; Dev acc: 0.147321; Test acc: 0.138298\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.562911; Dev loss 0.553389; Dev acc: 0.174107; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.663060; Dev loss 0.567357; Dev acc: 0.183036; Test acc: 0.124113\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.288311; Dev loss 0.591439; Dev acc: 0.187500; Test acc: 0.173759\n",
      "Iteration: 33\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.610276; Dev loss 0.550717; Dev acc: 0.183036; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.178718; Dev loss 0.550510; Dev acc: 0.294643; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.208575; Dev loss 0.578286; Dev acc: 0.133929; Test acc: 0.138298\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.235620; Dev loss 0.557925; Dev acc: 0.116071; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.568047; Dev loss 0.546579; Dev acc: 0.120536; Test acc: 0.163121\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.261282; Dev loss 0.540478; Dev acc: 0.120536; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.467040; Dev loss 0.543729; Dev acc: 0.299107; Test acc: 0.216312\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.473192; Dev loss 0.579599; Dev acc: 0.218750; Test acc: 0.372340\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.409681; Dev loss 0.560878; Dev acc: 0.227679; Test acc: 0.234043\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.303683; Dev loss 0.601668; Dev acc: 0.183036; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.859989; Dev loss 0.607670; Dev acc: 0.196429; Test acc: 0.120567\n",
      "Iteration: 34\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.563112; Dev loss 0.549368; Dev acc: 0.272321; Test acc: 0.265957\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.969997; Dev loss 0.520159; Dev acc: 0.223214; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.123853; Dev loss 0.535406; Dev acc: 0.058036; Test acc: 0.070922\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.192717; Dev loss 0.507173; Dev acc: 0.254464; Test acc: 0.283688\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.486111; Dev loss 0.505934; Dev acc: 0.285714; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.617586; Dev loss 0.514755; Dev acc: 0.236607; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.387652; Dev loss 0.507892; Dev acc: 0.223214; Test acc: 0.269504\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.226461; Dev loss 0.519977; Dev acc: 0.227679; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.416364; Dev loss 0.502124; Dev acc: 0.299107; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.165154; Dev loss 0.499203; Dev acc: 0.218750; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.698078; Dev loss 0.507285; Dev acc: 0.299107; Test acc: 0.322695\n",
      "Iteration: 35\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.696652; Dev loss 0.531636; Dev acc: 0.160714; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.464653; Dev loss 0.519792; Dev acc: 0.267857; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2; Loss 2.873949; Dev loss 0.522264; Dev acc: 0.156250; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.396905; Dev loss 0.527607; Dev acc: 0.071429; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.856721; Dev loss 0.526263; Dev acc: 0.075893; Test acc: 0.056738\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.356793; Dev loss 0.522733; Dev acc: 0.245536; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.747929; Dev loss 0.572050; Dev acc: 0.160714; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.692900; Dev loss 0.569006; Dev acc: 0.174107; Test acc: 0.205674\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.616079; Dev loss 0.637490; Dev acc: 0.227679; Test acc: 0.191489\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.425697; Dev loss 0.613332; Dev acc: 0.093750; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.807488; Dev loss 0.549280; Dev acc: 0.160714; Test acc: 0.180851\n",
      "Iteration: 36\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss nan; Dev loss nan; Dev acc: 0.026786; Test acc: 0.024823\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss nan; Dev loss nan; Dev acc: 0.035714; Test acc: 0.021277\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss nan; Dev loss nan; Dev acc: 0.017857; Test acc: 0.010638\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss nan; Dev loss nan; Dev acc: 0.022321; Test acc: 0.007092\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss nan; Dev loss nan; Dev acc: 0.031250; Test acc: 0.021277\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss nan; Dev loss nan; Dev acc: 0.026786; Test acc: 0.014184\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss nan; Dev loss nan; Dev acc: 0.017857; Test acc: 0.003546\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss nan; Dev loss nan; Dev acc: 0.013393; Test acc: 0.031915\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss nan; Dev loss nan; Dev acc: 0.026786; Test acc: 0.003546\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss nan; Dev loss nan; Dev acc: 0.022321; Test acc: 0.017730\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss nan; Dev loss nan; Dev acc: 0.044643; Test acc: 0.039007\n",
      "Iteration: 37\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.986559; Dev loss 0.563915; Dev acc: 0.053571; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.410625; Dev loss 0.535230; Dev acc: 0.258929; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.171595; Dev loss 0.524593; Dev acc: 0.236607; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.803438; Dev loss 0.519397; Dev acc: 0.205357; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.033517; Dev loss 0.514928; Dev acc: 0.250000; Test acc: 0.237589\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.406862; Dev loss 0.536051; Dev acc: 0.250000; Test acc: 0.308511\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.442912; Dev loss 0.525810; Dev acc: 0.098214; Test acc: 0.166667\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.319125; Dev loss 0.530779; Dev acc: 0.187500; Test acc: 0.280142\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.174645; Dev loss 0.518503; Dev acc: 0.276786; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.787603; Dev loss 0.525747; Dev acc: 0.276786; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.936739; Dev loss 0.517318; Dev acc: 0.196429; Test acc: 0.258865\n",
      "Iteration: 38\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.881341; Dev loss 0.514760; Dev acc: 0.241071; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.543343; Dev loss 0.559786; Dev acc: 0.089286; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.880256; Dev loss 0.510744; Dev acc: 0.303571; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.128686; Dev loss 0.510383; Dev acc: 0.303571; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.708543; Dev loss 0.513336; Dev acc: 0.267857; Test acc: 0.358156\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.798589; Dev loss 0.530693; Dev acc: 0.232143; Test acc: 0.386525\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.385342; Dev loss 0.514245; Dev acc: 0.285714; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.033103; Dev loss 0.522859; Dev acc: 0.281250; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.884413; Dev loss 0.506694; Dev acc: 0.303571; Test acc: 0.358156\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.869182; Dev loss 0.513169; Dev acc: 0.303571; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.081071; Dev loss 0.519238; Dev acc: 0.285714; Test acc: 0.336879\n",
      "Iteration: 39\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.924958; Dev loss 0.519832; Dev acc: 0.107143; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.011431; Dev loss 0.516365; Dev acc: 0.040179; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.945193; Dev loss 0.514678; Dev acc: 0.299107; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.466597; Dev loss 0.521030; Dev acc: 0.125000; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.797310; Dev loss 0.527124; Dev acc: 0.071429; Test acc: 0.085106\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.853043; Dev loss 0.524090; Dev acc: 0.223214; Test acc: 0.195035\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.791833; Dev loss 0.524717; Dev acc: 0.102679; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.728803; Dev loss 0.529158; Dev acc: 0.165179; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.621264; Dev loss 0.511382; Dev acc: 0.142857; Test acc: 0.124113\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.799137; Dev loss 0.505184; Dev acc: 0.254464; Test acc: 0.283688\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.727929; Dev loss 0.535499; Dev acc: 0.111607; Test acc: 0.198582\n",
      "Iteration: 40\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.156508; Dev loss 0.556411; Dev acc: 0.321429; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.078086; Dev loss 0.532673; Dev acc: 0.250000; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.795483; Dev loss 0.570857; Dev acc: 0.263393; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.259557; Dev loss 0.510609; Dev acc: 0.254464; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.628676; Dev loss 0.521690; Dev acc: 0.125000; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.599515; Dev loss 0.529956; Dev acc: 0.223214; Test acc: 0.304965\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.555154; Dev loss 0.525261; Dev acc: 0.111607; Test acc: 0.067376\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.355994; Dev loss 0.541016; Dev acc: 0.107143; Test acc: 0.138298\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.001342; Dev loss 0.528159; Dev acc: 0.133929; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.255211; Dev loss 0.525448; Dev acc: 0.191964; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.377117; Dev loss 0.533367; Dev acc: 0.102679; Test acc: 0.141844\n",
      "Iteration: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.882041; Dev loss 0.596777; Dev acc: 0.321429; Test acc: 0.304965\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.489127; Dev loss 0.558983; Dev acc: 0.330357; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.869060; Dev loss 0.524415; Dev acc: 0.236607; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.333192; Dev loss 0.525007; Dev acc: 0.285714; Test acc: 0.347518\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.246388; Dev loss 0.537609; Dev acc: 0.062500; Test acc: 0.081560\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.652913; Dev loss 0.540338; Dev acc: 0.285714; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.723825; Dev loss 0.516563; Dev acc: 0.308036; Test acc: 0.361702\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.789824; Dev loss 0.503898; Dev acc: 0.330357; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.909628; Dev loss 0.508673; Dev acc: 0.308036; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.337341; Dev loss 0.517875; Dev acc: 0.093750; Test acc: 0.124113\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.332109; Dev loss 0.517992; Dev acc: 0.294643; Test acc: 0.347518\n",
      "Iteration: 42\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.308965; Dev loss 0.552110; Dev acc: 0.263393; Test acc: 0.368794\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.473859; Dev loss 0.542729; Dev acc: 0.138393; Test acc: 0.209220\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.659322; Dev loss 0.548540; Dev acc: 0.227679; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.045441; Dev loss 0.530570; Dev acc: 0.156250; Test acc: 0.219858\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.335493; Dev loss 0.524535; Dev acc: 0.272321; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.669685; Dev loss 0.512507; Dev acc: 0.075893; Test acc: 0.106383\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.435263; Dev loss 0.515550; Dev acc: 0.147321; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.342910; Dev loss 0.522205; Dev acc: 0.276786; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.987093; Dev loss 0.548927; Dev acc: 0.196429; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.456473; Dev loss 0.510918; Dev acc: 0.138393; Test acc: 0.191489\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.770020; Dev loss 0.540704; Dev acc: 0.169643; Test acc: 0.237589\n",
      "Iteration: 43\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.418484; Dev loss 0.540915; Dev acc: 0.071429; Test acc: 0.070922\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.446314; Dev loss 0.530859; Dev acc: 0.138393; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.194443; Dev loss 0.519618; Dev acc: 0.303571; Test acc: 0.382979\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.219880; Dev loss 0.519923; Dev acc: 0.232143; Test acc: 0.124113\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.947235; Dev loss 0.518831; Dev acc: 0.223214; Test acc: 0.351064\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.472129; Dev loss 0.512643; Dev acc: 0.294643; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.664532; Dev loss 0.529101; Dev acc: 0.321429; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.495028; Dev loss 0.524919; Dev acc: 0.200893; Test acc: 0.244681\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.666855; Dev loss 0.519644; Dev acc: 0.290179; Test acc: 0.269504\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.365401; Dev loss 0.526137; Dev acc: 0.263393; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.239484; Dev loss 0.533693; Dev acc: 0.196429; Test acc: 0.145390\n",
      "Iteration: 44\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss nan; Dev loss nan; Dev acc: 0.022321; Test acc: 0.031915\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss nan; Dev loss nan; Dev acc: 0.035714; Test acc: 0.028369\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss nan; Dev loss nan; Dev acc: 0.017857; Test acc: 0.017730\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss nan; Dev loss nan; Dev acc: 0.031250; Test acc: 0.010638\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss nan; Dev loss nan; Dev acc: 0.026786; Test acc: 0.010638\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss nan; Dev loss nan; Dev acc: 0.017857; Test acc: 0.035461\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss nan; Dev loss nan; Dev acc: 0.026786; Test acc: 0.056738\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss nan; Dev loss nan; Dev acc: 0.022321; Test acc: 0.010638\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss nan; Dev loss nan; Dev acc: 0.008929; Test acc: 0.046099\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss nan; Dev loss nan; Dev acc: 0.022321; Test acc: 0.039007\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss nan; Dev loss nan; Dev acc: 0.017857; Test acc: 0.017730\n",
      "Iteration: 45\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.730033; Dev loss 0.522840; Dev acc: 0.138393; Test acc: 0.109929\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.686049; Dev loss 0.573576; Dev acc: 0.165179; Test acc: 0.166667\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.477411; Dev loss 0.571391; Dev acc: 0.191964; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.464765; Dev loss 0.558945; Dev acc: 0.129464; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.300069; Dev loss 0.598068; Dev acc: 0.116071; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.757677; Dev loss 0.545268; Dev acc: 0.107143; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.822166; Dev loss 0.620683; Dev acc: 0.093750; Test acc: 0.056738\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.834121; Dev loss 0.592209; Dev acc: 0.111607; Test acc: 0.152482\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.874711; Dev loss 0.648208; Dev acc: 0.147321; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.458207; Dev loss 0.781385; Dev acc: 0.178571; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.180543; Dev loss 0.751536; Dev acc: 0.236607; Test acc: 0.184397\n",
      "Iteration: 46\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.402099; Dev loss 0.556806; Dev acc: 0.267857; Test acc: 0.255319\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.551590; Dev loss 0.547307; Dev acc: 0.258929; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.885238; Dev loss 0.529809; Dev acc: 0.232143; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.968243; Dev loss 0.543363; Dev acc: 0.263393; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.524931; Dev loss 0.516271; Dev acc: 0.267857; Test acc: 0.336879\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.673878; Dev loss 0.537372; Dev acc: 0.227679; Test acc: 0.280142\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.372056; Dev loss 0.543974; Dev acc: 0.236607; Test acc: 0.262411\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.771743; Dev loss 0.523856; Dev acc: 0.111607; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8; Loss 2.714374; Dev loss 0.584934; Dev acc: 0.062500; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.538305; Dev loss 0.612669; Dev acc: 0.084821; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.586139; Dev loss 0.549716; Dev acc: 0.245536; Test acc: 0.216312\n",
      "Iteration: 47\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.713847; Dev loss 0.521943; Dev acc: 0.058036; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.750734; Dev loss 0.520496; Dev acc: 0.325893; Test acc: 0.397163\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.696030; Dev loss 0.525358; Dev acc: 0.035714; Test acc: 0.078014\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.992239; Dev loss 0.511267; Dev acc: 0.258929; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.520736; Dev loss 0.509007; Dev acc: 0.263393; Test acc: 0.265957\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.157120; Dev loss 0.505980; Dev acc: 0.276786; Test acc: 0.365248\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.645482; Dev loss 0.525303; Dev acc: 0.241071; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.892752; Dev loss 0.519169; Dev acc: 0.254464; Test acc: 0.382979\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.415632; Dev loss 0.507887; Dev acc: 0.075893; Test acc: 0.124113\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.696973; Dev loss 0.506247; Dev acc: 0.299107; Test acc: 0.329787\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.711352; Dev loss 0.514592; Dev acc: 0.214286; Test acc: 0.308511\n",
      "Iteration: 48\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.381154; Dev loss 0.554120; Dev acc: 0.187500; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.872597; Dev loss 0.525419; Dev acc: 0.080357; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 3.842055; Dev loss 0.551680; Dev acc: 0.276786; Test acc: 0.407801\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.610683; Dev loss 0.530375; Dev acc: 0.191964; Test acc: 0.287234\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.167978; Dev loss 0.531007; Dev acc: 0.062500; Test acc: 0.109929\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.765073; Dev loss 0.528322; Dev acc: 0.125000; Test acc: 0.237589\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.358464; Dev loss 0.552134; Dev acc: 0.218750; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.578762; Dev loss 0.525796; Dev acc: 0.187500; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.214459; Dev loss 0.538408; Dev acc: 0.205357; Test acc: 0.230496\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.080790; Dev loss 0.555691; Dev acc: 0.133929; Test acc: 0.145390\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.109398; Dev loss 0.572933; Dev acc: 0.209821; Test acc: 0.223404\n",
      "Iteration: 49\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.798043; Dev loss 0.516023; Dev acc: 0.250000; Test acc: 0.219858\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.515654; Dev loss 0.525515; Dev acc: 0.272321; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.894319; Dev loss 0.518839; Dev acc: 0.258929; Test acc: 0.358156\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.060336; Dev loss 0.526267; Dev acc: 0.200893; Test acc: 0.251773\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.291149; Dev loss 0.542253; Dev acc: 0.299107; Test acc: 0.390071\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.842612; Dev loss 0.544571; Dev acc: 0.236607; Test acc: 0.237589\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.311467; Dev loss 0.528233; Dev acc: 0.205357; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.650093; Dev loss 0.526248; Dev acc: 0.075893; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.796262; Dev loss 0.531563; Dev acc: 0.258929; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.529484; Dev loss 0.541204; Dev acc: 0.066964; Test acc: 0.106383\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.670957; Dev loss 0.565241; Dev acc: 0.214286; Test acc: 0.262411\n",
      "Iteration: 50\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.845222; Dev loss 0.653946; Dev acc: 0.120536; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.614681; Dev loss 0.594646; Dev acc: 0.245536; Test acc: 0.255319\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.649702; Dev loss 0.575948; Dev acc: 0.084821; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.730336; Dev loss 0.639799; Dev acc: 0.125000; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.108338; Dev loss 0.535988; Dev acc: 0.160714; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.513595; Dev loss 0.543606; Dev acc: 0.241071; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.387879; Dev loss 0.645747; Dev acc: 0.138393; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.372566; Dev loss 0.559669; Dev acc: 0.218750; Test acc: 0.262411\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.486573; Dev loss 0.553314; Dev acc: 0.312500; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.853369; Dev loss 0.536459; Dev acc: 0.107143; Test acc: 0.138298\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.362276; Dev loss 0.521205; Dev acc: 0.245536; Test acc: 0.265957\n",
      "Iteration: 51\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.803635; Dev loss 0.544397; Dev acc: 0.183036; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.544904; Dev loss 0.541009; Dev acc: 0.102679; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.887143; Dev loss 0.590689; Dev acc: 0.102679; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.690107; Dev loss 0.558062; Dev acc: 0.107143; Test acc: 0.156028\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.062279; Dev loss 0.612614; Dev acc: 0.107143; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.671981; Dev loss 0.605282; Dev acc: 0.165179; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.280845; Dev loss 0.670291; Dev acc: 0.080357; Test acc: 0.148936\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.981157; Dev loss 0.690824; Dev acc: 0.142857; Test acc: 0.244681\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.559673; Dev loss 0.611228; Dev acc: 0.133929; Test acc: 0.095745\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.854775; Dev loss 0.593195; Dev acc: 0.133929; Test acc: 0.102837\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.596416; Dev loss 0.627154; Dev acc: 0.160714; Test acc: 0.099291\n",
      "Iteration: 52\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.497961; Dev loss 0.503086; Dev acc: 0.142857; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.622887; Dev loss 0.529737; Dev acc: 0.263393; Test acc: 0.382979\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.534005; Dev loss 0.511224; Dev acc: 0.209821; Test acc: 0.322695\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.696862; Dev loss 0.506723; Dev acc: 0.111607; Test acc: 0.148936\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.401783; Dev loss 0.502464; Dev acc: 0.348214; Test acc: 0.333333\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.461040; Dev loss 0.517026; Dev acc: 0.062500; Test acc: 0.099291\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.748502; Dev loss 0.512319; Dev acc: 0.178571; Test acc: 0.269504\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.614578; Dev loss 0.513208; Dev acc: 0.174107; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.769385; Dev loss 0.513317; Dev acc: 0.232143; Test acc: 0.390071\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.800626; Dev loss 0.514328; Dev acc: 0.236607; Test acc: 0.315603\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.020709; Dev loss 0.503438; Dev acc: 0.321429; Test acc: 0.336879\n",
      "Iteration: 53\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.385186; Dev loss 0.574607; Dev acc: 0.245536; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.349816; Dev loss 0.519760; Dev acc: 0.093750; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.990883; Dev loss 0.556697; Dev acc: 0.178571; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.656879; Dev loss 0.552073; Dev acc: 0.218750; Test acc: 0.209220\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.429888; Dev loss 0.558295; Dev acc: 0.258929; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 3.726279; Dev loss 0.564002; Dev acc: 0.303571; Test acc: 0.333333\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.771754; Dev loss 0.549715; Dev acc: 0.107143; Test acc: 0.170213\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.037513; Dev loss 0.552278; Dev acc: 0.156250; Test acc: 0.180851\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.483148; Dev loss 0.573721; Dev acc: 0.120536; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.232157; Dev loss 0.578871; Dev acc: 0.156250; Test acc: 0.258865\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.488870; Dev loss 0.616928; Dev acc: 0.116071; Test acc: 0.166667\n",
      "Iteration: 54\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.440319; Dev loss 0.544106; Dev acc: 0.285714; Test acc: 0.361702\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.716661; Dev loss 0.516387; Dev acc: 0.058036; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 4.118302; Dev loss 0.520333; Dev acc: 0.276786; Test acc: 0.375887\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.888949; Dev loss 0.504906; Dev acc: 0.299107; Test acc: 0.354610\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.692832; Dev loss 0.529685; Dev acc: 0.281250; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.922050; Dev loss 0.516157; Dev acc: 0.308036; Test acc: 0.301418\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.200298; Dev loss 0.524438; Dev acc: 0.294643; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.785585; Dev loss 0.514420; Dev acc: 0.290179; Test acc: 0.244681\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.772436; Dev loss 0.526141; Dev acc: 0.062500; Test acc: 0.109929\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.080965; Dev loss 0.526963; Dev acc: 0.227679; Test acc: 0.308511\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.571782; Dev loss 0.527906; Dev acc: 0.281250; Test acc: 0.280142\n",
      "Iteration: 55\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.134131; Dev loss 0.618951; Dev acc: 0.183036; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.677537; Dev loss 0.567703; Dev acc: 0.241071; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.702853; Dev loss 0.560640; Dev acc: 0.174107; Test acc: 0.127660\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.332538; Dev loss 0.587952; Dev acc: 0.120536; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.801108; Dev loss 0.604765; Dev acc: 0.165179; Test acc: 0.244681\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.800658; Dev loss 0.575156; Dev acc: 0.214286; Test acc: 0.283688\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.161681; Dev loss 0.557577; Dev acc: 0.129464; Test acc: 0.184397\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.265391; Dev loss 0.554310; Dev acc: 0.160714; Test acc: 0.141844\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.912162; Dev loss 0.603891; Dev acc: 0.116071; Test acc: 0.141844\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.979355; Dev loss 0.613647; Dev acc: 0.169643; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.566402; Dev loss 0.589437; Dev acc: 0.133929; Test acc: 0.180851\n",
      "Iteration: 56\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.483655; Dev loss 0.522878; Dev acc: 0.308036; Test acc: 0.382979\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.794334; Dev loss 0.542462; Dev acc: 0.102679; Test acc: 0.092199\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.990175; Dev loss 0.518106; Dev acc: 0.169643; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.985553; Dev loss 0.519201; Dev acc: 0.156250; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.372533; Dev loss 0.527179; Dev acc: 0.196429; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.816451; Dev loss 0.519832; Dev acc: 0.294643; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.706915; Dev loss 0.541175; Dev acc: 0.258929; Test acc: 0.297872\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.067132; Dev loss 0.527733; Dev acc: 0.200893; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.808209; Dev loss 0.511783; Dev acc: 0.245536; Test acc: 0.273050\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.906958; Dev loss 0.518245; Dev acc: 0.142857; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.304222; Dev loss 0.525309; Dev acc: 0.116071; Test acc: 0.102837\n",
      "Iteration: 57\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.358665; Dev loss 0.557195; Dev acc: 0.062500; Test acc: 0.113475\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.048762; Dev loss 0.607644; Dev acc: 0.169643; Test acc: 0.131206\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.392230; Dev loss 0.717148; Dev acc: 0.241071; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.510488; Dev loss 0.605647; Dev acc: 0.102679; Test acc: 0.106383\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.809066; Dev loss 0.550950; Dev acc: 0.160714; Test acc: 0.159574\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.762952; Dev loss 0.532522; Dev acc: 0.169643; Test acc: 0.177305\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 3.014771; Dev loss 0.553630; Dev acc: 0.102679; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.377872; Dev loss 0.525807; Dev acc: 0.196429; Test acc: 0.202128\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 3.076380; Dev loss 0.532028; Dev acc: 0.272321; Test acc: 0.226950\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.303396; Dev loss 0.530365; Dev acc: 0.236607; Test acc: 0.265957\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.418481; Dev loss 0.521703; Dev acc: 0.276786; Test acc: 0.336879\n",
      "Iteration: 58\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.238904; Dev loss 0.607703; Dev acc: 0.267857; Test acc: 0.393617\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1; Loss 2.328716; Dev loss 0.647248; Dev acc: 0.133929; Test acc: 0.180851\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.988153; Dev loss 0.538811; Dev acc: 0.120536; Test acc: 0.088652\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.337624; Dev loss 0.533913; Dev acc: 0.062500; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 3.191878; Dev loss 0.538181; Dev acc: 0.071429; Test acc: 0.070922\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.611320; Dev loss 0.516953; Dev acc: 0.147321; Test acc: 0.120567\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.172477; Dev loss 0.526172; Dev acc: 0.209821; Test acc: 0.283688\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 3.373095; Dev loss 0.560164; Dev acc: 0.129464; Test acc: 0.134752\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.835290; Dev loss 0.544011; Dev acc: 0.267857; Test acc: 0.294326\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.351702; Dev loss 0.534774; Dev acc: 0.116071; Test acc: 0.180851\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.429501; Dev loss 0.551039; Dev acc: 0.098214; Test acc: 0.159574\n",
      "Iteration: 59\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 3.123216; Dev loss 0.519803; Dev acc: 0.214286; Test acc: 0.258865\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 2.939892; Dev loss 0.540786; Dev acc: 0.263393; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.399630; Dev loss 0.533810; Dev acc: 0.232143; Test acc: 0.347518\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 3.052734; Dev loss 0.544676; Dev acc: 0.276786; Test acc: 0.361702\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.049973; Dev loss 0.524102; Dev acc: 0.093750; Test acc: 0.152482\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.979990; Dev loss 0.535172; Dev acc: 0.263393; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.417216; Dev loss 0.521449; Dev acc: 0.308036; Test acc: 0.343972\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.967185; Dev loss 0.509860; Dev acc: 0.312500; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.742660; Dev loss 0.529030; Dev acc: 0.241071; Test acc: 0.290780\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 2.868807; Dev loss 0.511376; Dev acc: 0.285714; Test acc: 0.312057\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 3.042985; Dev loss 0.518052; Dev acc: 0.294643; Test acc: 0.280142\n",
      "Iteration: 60\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 0; Loss 2.401431; Dev loss 0.516680; Dev acc: 0.316964; Test acc: 0.248227\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 1; Loss 3.171722; Dev loss 0.527668; Dev acc: 0.254464; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 2; Loss 2.742907; Dev loss 0.523691; Dev acc: 0.200893; Test acc: 0.340426\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 3; Loss 2.360121; Dev loss 0.533812; Dev acc: 0.308036; Test acc: 0.319149\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 4; Loss 2.534414; Dev loss 0.505759; Dev acc: 0.312500; Test acc: 0.276596\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 5; Loss 2.768685; Dev loss 0.537127; Dev acc: 0.058036; Test acc: 0.067376\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 6; Loss 2.813159; Dev loss 0.541461; Dev acc: 0.245536; Test acc: 0.326241\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 7; Loss 2.136286; Dev loss 0.547495; Dev acc: 0.093750; Test acc: 0.117021\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 8; Loss 2.413609; Dev loss 0.537152; Dev acc: 0.151786; Test acc: 0.173759\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 9; Loss 3.523538; Dev loss 0.548279; Dev acc: 0.227679; Test acc: 0.255319\n",
      "Training...\n",
      "Evaluating dev...\n",
      "Evaluating test..\n",
      "Epoch 10; Loss 2.698442; Dev loss 0.545449; Dev acc: 0.209821; Test acc: 0.297872\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4a16e095cac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m df_2 = pd.DataFrame({\"droprate\": best_dropout, \"learning_rates\": best_learning_rate,\n\u001b[0;32m     91\u001b[0m                      \u001b[1;34m\"hidden_dim\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbest_hidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"v_dim\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbest_v_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                      \"dev_accuracy\": best_dev_acc, \"test_accuracy\": best_test_acc})\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DATN_results_target_best_YD.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             raise ValueError('If using all scalar values, you must pass'\n\u001b[0m\u001b[0;32m    309\u001b[0m                              ' an index')\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "dropout_min = 0.2\n",
    "dropout_max = 0.8\n",
    "\n",
    "learning_rate_min = 0.0001\n",
    "learning_rate_max = 0.01\n",
    "\n",
    "hidden_dim_min = 50\n",
    "hidden_dim_max = 300\n",
    "\n",
    "v_dim_min = 5\n",
    "v_dim_max = 30\n",
    "embedding_dim = 300\n",
    "\n",
    "dropouts = []\n",
    "learning_rates = []\n",
    "hidden_dims = []\n",
    "v_dims = []\n",
    "dev_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "best_dev_acc = 0\n",
    "best_test_acc = 0\n",
    "best_hidden_dim = 0\n",
    "best_v_dim = 0\n",
    "best_learning_rate = 0\n",
    "best_dropout = 0\n",
    "best_m_target = None\n",
    "target_attn_poems = None\n",
    "best_H_target_p = None\n",
    "\n",
    "for i in range(60):\n",
    "    \n",
    "    print(\"Iteration: {}\".format(i+1))\n",
    "    \n",
    "    dropout = np.random.uniform(dropout_min, dropout_max)\n",
    "    learning_rate = 10**np.random.uniform(np.log10(learning_rate_min), np.log10(learning_rate_max))\n",
    "#     hidden_dim = np.random.randint(hidden_dim_min, hidden_dim_max)\n",
    "    v_dim = np.random.randint(v_dim_min, v_dim_max)\n",
    "\n",
    "\n",
    "\n",
    "    m_target_p = BiLSTMTargetNet_withMLP(vocab_size = len(TEXT.vocab), embedding_dim = embedding_dim, \n",
    "                                   hidden_dim = hidden_dim_src, label_size=label_size, v_dim = v_dim,\n",
    "                                   pretrained_vec=TEXT.vocab.vectors, use_gpu = True, dropout = dropout)\n",
    "    m_target_p.to(\"cuda\")\n",
    "\n",
    "    opt_t = torch.optim.Adam(filter(lambda p: p.requires_grad, m_target_p.parameters()), learning_rate)\n",
    "\n",
    "    dev_acc, test_acc, src_attention_p, H_src_p = training_loop_DATN_full(batch_size = batch_size, \n",
    "                                                                num_epochs = 10, src_model = m_source_p, \n",
    "                                                                tgt_model = m_target_p,\n",
    "                                                                loss_ = F.kl_div, optim_src = None, optim_tgt = opt_t, \n",
    "                                                                training_iter=train_batch, lambda_ = 0.05, \n",
    "                                                                dev_iter=valid_batch, test_iter = test_batch, \n",
    "                                                                source_flag = True, verbose = True, src_learn_flag = False)\n",
    "\n",
    "    dropouts.append(dropout)\n",
    "    learning_rates.append(learning_rate)\n",
    "    hidden_dims.append(hidden_dim_src)\n",
    "    v_dims.append(v_dim)\n",
    "    dev_accuracies.append(dev_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    try:\n",
    "        check = dev_accuracies[-1] > dev_accuracies[-2]\n",
    "    except:\n",
    "        check = dev_accuracies[-1] > 0\n",
    "\n",
    "    if check:\n",
    "\n",
    "        best_dev_acc = dev_acc\n",
    "        best_learning_rate = learning_rates[-1]\n",
    "        best_hidden_dim = hidden_dims[-1]\n",
    "        best_v_dim  = v_dims[-1]\n",
    "        best_dropout = dropouts[-1]\n",
    "        best_m_target = m_target_p\n",
    "        best_test_acc = test_acc\n",
    "#         target_attn_poems = target_attention\n",
    "#         best_H_target_p = H_target_p\n",
    "\n",
    "    df = pd.DataFrame({\"droprate\": dropouts, \"learning_rates\": learning_rates, \n",
    "                       \"hidden_dim\": hidden_dims, \"v_dim\": v_dims, \n",
    "                       \"dev_accuracy\": dev_accuracies, \"test_accuracy\": test_accuracies})\n",
    "    df.to_csv(\"DATN_results_YD.csv\")\n",
    "\n",
    "df = pd.DataFrame({\"droprate\": dropouts, \"learning_rates\": learning_rates, \n",
    "                   \"hidden_dim\": hidden_dims, \"v_dim\": v_dims, \n",
    "                   \"dev_accuracy\": dev_accuracies, \"test_accuracy\": test_accuracies})\n",
    "\n",
    "df_2 = pd.DataFrame({\"droprate\": best_dropout, \"learning_rates\": best_learning_rate,\n",
    "                     \"hidden_dim\": best_hidden_dim, \"v_dim\": best_v_dim, \n",
    "                     \"dev_accuracy\": best_dev_acc, \"test_accuracy\": best_test_acc})\n",
    "\n",
    "df_2.to_csv(\"DATN_results_target_best_YD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>droprate</th>\n",
       "      <th>learning_rates</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>v_dim</th>\n",
       "      <th>dev_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493469</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>183</td>\n",
       "      <td>17</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.223404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749746</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>183</td>\n",
       "      <td>11</td>\n",
       "      <td>0.200893</td>\n",
       "      <td>0.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.405397</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>183</td>\n",
       "      <td>16</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.315603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.646440</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>183</td>\n",
       "      <td>15</td>\n",
       "      <td>0.263393</td>\n",
       "      <td>0.326241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.793815</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.349833</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>183</td>\n",
       "      <td>16</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.269504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.714568</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.290780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.432629</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>183</td>\n",
       "      <td>25</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.304965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.608916</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>183</td>\n",
       "      <td>27</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.312057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.297347</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>183</td>\n",
       "      <td>19</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.304965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.632536</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>183</td>\n",
       "      <td>16</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.315603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.238817</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.287234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.469549</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>0.316964</td>\n",
       "      <td>0.322695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.374146</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>183</td>\n",
       "      <td>27</td>\n",
       "      <td>0.290179</td>\n",
       "      <td>0.216312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.592902</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>183</td>\n",
       "      <td>6</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.316057</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.326241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.227565</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>183</td>\n",
       "      <td>18</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.365248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.443474</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>183</td>\n",
       "      <td>26</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.273050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.310312</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>183</td>\n",
       "      <td>14</td>\n",
       "      <td>0.316964</td>\n",
       "      <td>0.375887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.776537</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>183</td>\n",
       "      <td>17</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.329787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.788243</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "      <td>0.290179</td>\n",
       "      <td>0.276596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.407853</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>183</td>\n",
       "      <td>26</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.386525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.481204</td>\n",
       "      <td>0.007604</td>\n",
       "      <td>183</td>\n",
       "      <td>19</td>\n",
       "      <td>0.263393</td>\n",
       "      <td>0.223404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.569277</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>183</td>\n",
       "      <td>25</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.202128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.618639</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>183</td>\n",
       "      <td>20</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.336879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.607218</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>183</td>\n",
       "      <td>14</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.640834</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>183</td>\n",
       "      <td>18</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.273050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.490178</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>183</td>\n",
       "      <td>7</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.343972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.555807</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>183</td>\n",
       "      <td>9</td>\n",
       "      <td>0.272321</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.238612</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>183</td>\n",
       "      <td>20</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.258865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.267743</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>183</td>\n",
       "      <td>19</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.280142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.455457</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>183</td>\n",
       "      <td>7</td>\n",
       "      <td>0.227679</td>\n",
       "      <td>0.351064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.451607</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>183</td>\n",
       "      <td>27</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>0.216312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.249584</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>183</td>\n",
       "      <td>28</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.319676</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.326241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.432150</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>183</td>\n",
       "      <td>29</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.039007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.789400</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.343972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.765737</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>183</td>\n",
       "      <td>21</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>0.301418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.782674</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>183</td>\n",
       "      <td>14</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.301418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.366179</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>183</td>\n",
       "      <td>28</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.610916</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>183</td>\n",
       "      <td>7</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.329787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.206193</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>183</td>\n",
       "      <td>12</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.312057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.311056</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>183</td>\n",
       "      <td>29</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.028369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>183</td>\n",
       "      <td>14</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>0.184397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>183</td>\n",
       "      <td>26</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.506816</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>183</td>\n",
       "      <td>28</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.397163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.507659</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>183</td>\n",
       "      <td>17</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.407801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.507726</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>183</td>\n",
       "      <td>6</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>0.390071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.789789</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>183</td>\n",
       "      <td>23</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.322695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.403275</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>183</td>\n",
       "      <td>11</td>\n",
       "      <td>0.183036</td>\n",
       "      <td>0.134752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.666345</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>183</td>\n",
       "      <td>22</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.340904</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>183</td>\n",
       "      <td>20</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.268008</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.301418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.641169</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>183</td>\n",
       "      <td>18</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.312057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.220457</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>0.308036</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.753293</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>183</td>\n",
       "      <td>26</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.336879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.598578</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>183</td>\n",
       "      <td>11</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.393617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.589545</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>183</td>\n",
       "      <td>20</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.783364</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>183</td>\n",
       "      <td>9</td>\n",
       "      <td>0.316964</td>\n",
       "      <td>0.248227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    droprate  learning_rates  hidden_dim  v_dim  dev_accuracy  test_accuracy\n",
       "0   0.493469        0.007602         183     17      0.267857       0.223404\n",
       "1   0.749746        0.007738         183     11      0.200893       0.297872\n",
       "2   0.405397        0.000465         183     16      0.348214       0.315603\n",
       "3   0.646440        0.006163         183     15      0.263393       0.326241\n",
       "4   0.793815        0.000242         183     13      0.281250       0.319149\n",
       "5   0.349833        0.004270         183     16      0.294643       0.269504\n",
       "6   0.714568        0.000745         183     10      0.348214       0.290780\n",
       "7   0.432629        0.000125         183     25      0.321429       0.304965\n",
       "8   0.608916        0.000354         183     27      0.308036       0.312057\n",
       "9   0.297347        0.000734         183     19      0.325893       0.304965\n",
       "10  0.632536        0.000158         183     16      0.325893       0.315603\n",
       "11  0.238817        0.002332         183      8      0.258929       0.287234\n",
       "12  0.469549        0.000307         183      5      0.316964       0.322695\n",
       "13  0.374146        0.000756         183     27      0.290179       0.216312\n",
       "14  0.592902        0.003419         183      6      0.281250       0.319149\n",
       "15  0.316057        0.000203         183     10      0.294643       0.326241\n",
       "16  0.227565        0.000436         183     18      0.281250       0.365248\n",
       "17  0.443474        0.003688         183     26      0.303571       0.273050\n",
       "18  0.310312        0.004872         183     14      0.316964       0.375887\n",
       "19  0.776537        0.000589         183     17      0.308036       0.329787\n",
       "20  0.788243        0.000735         183     10      0.290179       0.276596\n",
       "21  0.407853        0.004654         183     26      0.294643       0.386525\n",
       "22  0.481204        0.007604         183     19      0.263393       0.223404\n",
       "23  0.569277        0.006866         183     25      0.205357       0.202128\n",
       "24  0.618639        0.007726         183     20      0.308036       0.336879\n",
       "25  0.607218        0.000192         183     14      0.312500       0.319149\n",
       "26  0.640834        0.000111         183     18      0.308036       0.273050\n",
       "27  0.490178        0.001334         183      7      0.308036       0.343972\n",
       "28  0.555807        0.000880         183      9      0.272321       0.382979\n",
       "29  0.238612        0.005079         183     20      0.276786       0.258865\n",
       "30  0.267743        0.000102         183     19      0.303571       0.280142\n",
       "31  0.455457        0.003194         183      7      0.227679       0.351064\n",
       "32  0.451607        0.003756         183     27      0.299107       0.216312\n",
       "33  0.249584        0.000212         183     28      0.299107       0.340426\n",
       "34  0.319676        0.002347         183     10      0.267857       0.326241\n",
       "35  0.432150        0.000688         183     29      0.044643       0.039007\n",
       "36  0.789400        0.001149         183     13      0.276786       0.343972\n",
       "37  0.673694        0.000121         183      8      0.303571       0.340426\n",
       "38  0.765737        0.001178         183     21      0.299107       0.301418\n",
       "39  0.782674        0.002656         183     14      0.321429       0.301418\n",
       "40  0.366179        0.000259         183     28      0.330357       0.319149\n",
       "41  0.610916        0.000506         183      7      0.276786       0.329787\n",
       "42  0.206193        0.000481         183     12      0.321429       0.312057\n",
       "43  0.311056        0.000849         183     29      0.035714       0.028369\n",
       "44  0.237915        0.004769         183     14      0.236607       0.184397\n",
       "45  0.231045        0.001202         183     26      0.267857       0.255319\n",
       "46  0.506816        0.000123         183     28      0.325893       0.397163\n",
       "47  0.507659        0.001455         183     17      0.276786       0.407801\n",
       "48  0.507726        0.001113         183      6      0.299107       0.390071\n",
       "49  0.789789        0.007620         183     23      0.312500       0.322695\n",
       "50  0.403275        0.004953         183     11      0.183036       0.134752\n",
       "51  0.666345        0.000186         183     22      0.348214       0.333333\n",
       "52  0.340904        0.002936         183     20      0.303571       0.333333\n",
       "53  0.268008        0.000207         183      5      0.308036       0.301418\n",
       "54  0.641169        0.004175         183     18      0.241071       0.312057\n",
       "55  0.220457        0.000986         183     13      0.308036       0.382979\n",
       "56  0.753293        0.005567         183     26      0.276786       0.336879\n",
       "57  0.598578        0.001999         183     11      0.267857       0.393617\n",
       "58  0.589545        0.000119         183     20      0.312500       0.319149\n",
       "59  0.783364        0.002044         183      9      0.316964       0.248227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(s.squeeze(0), t.squeeze(0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor([2, 1, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t.topk(2).indices == s.topk(2).indices).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = torch.tensor([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.topk(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
